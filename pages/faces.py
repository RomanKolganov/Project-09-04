import streamlit as st
import torch
from PIL import Image
import numpy as np
import requests
from io import BytesIO
import cv2

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
weights_path = 'models/best_faces.pt'
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
model = torch.hub.load('ultralytics/yolov5', 'custom', path=weights_path, force_reload=True)
model.to(device).eval()

st.title("–î–µ—Ç–µ–∫—Ü–∏—è –∏ –º–∞—Å–∫–∏—Ä–æ–≤–∫–∞ –ª–∏—Ü üé≠")
st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
uploaded_files = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...", type=["jpg", "png", "jpeg"], accept_multiple_files=True)

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ –ø–æ –ø—Ä—è–º—ã–º —Å—Å—ã–ª–∫–∞–º
urls = st.text_area("–ò–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–∫–∞–∂–¥—É—é —Å—Å—ã–ª–∫—É —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏):", height=150)

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—Ä–æ–≥–∞ –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ —Ä–∞–º–æ–∫
# threshold = st.slider("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–æ—Ä–æ–≥ –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ —Ä–∞–º–æ–∫:", 0.0, 1.0, 0.5)
threshold = 0.5

images = []

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
if uploaded_files:
    for uploaded_file in uploaded_files:
        image = Image.open(uploaded_file)
        images.append(image)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –ø–æ —Å—Å—ã–ª–∫–∞–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
if urls:
    try:
        url_list = urls.splitlines()
        for url in url_list:
            response = requests.get(url.strip())
            image = Image.open(BytesIO(response.content))
            images.append(image)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ —Å—Å—ã–ª–∫–µ: {e}")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
for i, image in enumerate(images):  # –ò—Å–ø–æ–ª—å–∑—É–µ–º enumerate –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –º–æ–¥–µ–ª–∏ –∏ –≤—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    img_np = np.array(image)

    with torch.no_grad():
        results = model(img_np)

    detections = results.xyxy[0]

    for *bbox, conf, cls in detections:
        if conf >= threshold:
            x1, y1, x2, y2 = map(int, bbox)

            # –ú–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–ª–∞—Å—Ç–∏ —Å–æ —Å—Ç—Ä–µ–º–ª–µ–Ω–∏–µ–º (–±–ª—é—Ä)
            mask = img_np[y1:y2, x1:x2]
            blur_mask = cv2.GaussianBlur(mask, (89, 89), 0)
            img_np[y1:y2, x1:x2] = blur_mask

    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    st.image(img_np, caption="–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ä–∞–∑–º—ã—Ç–æ–π –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç—å—é", use_column_width=True)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    output_image_path = f'output_image_{i}.png'  # –£–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    Image.fromarray(img_np).save(output_image_path)

    # –ö–Ω–æ–ø–∫–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –∫–ª—é—á–æ–º
    with open(output_image_path, "rb") as file:
        st.download_button(label="–°–∫–∞—á–∞—Ç—å –∏—Ç–æ–≥–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", data=file, file_name=f"output_image_{i}.png", mime="image/png", key=f"download_button_{i}")  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á
st.write('')
st.write('')
st.write('')
st.markdown("–°–µ—Ä–≤–∏—Å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º YOLOv5:")
st.write('- 5 —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è')
st.write('- 16.7 —Ç—ã—Å—è—á –∫–∞—Ä—Ç–∏–Ω–æ–∫ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ')
st.image('Images/faces_metrics/PR_curve_faces.png', use_column_width=True)
st.image('Images/faces_metrics/confusion_matrix_faces.png', use_column_width=True)
st.image('Images/faces_metrics/results_faces.png', use_column_width=True)